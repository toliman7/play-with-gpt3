{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed146d0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lib.gpt3 import GPT\n",
    "import openai\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "gpt = GPT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9be5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Playing with GPT-3\n",
    "\n",
    "\n",
    " with Daniel Steger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7adbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " * What is GPT-3?\n",
    " * Playground\n",
    " * Critics\n",
    " * Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5d068",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## What is GPT-3? \n",
    " \n",
    "  * GPT-3 means \"Generative pre-trained transformer\"\n",
    "  * Natural language processing (NLP) especially the problem of machine translation\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f78ad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ### Basic concepts:\n",
    "  * Self-attention\n",
    "  * Transformer\n",
    "  * Unattended pre-training on huge data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1ba0b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recurrent neuronal networks (RNNs)\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" />\n",
    "\n",
    "From [[1]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269f3a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://jalammar.github.io/images/seq2seq_6.mp4\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb30a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem of long-term dependencies\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png\" />\n",
    "\n",
    "From [[1]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593bec0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Attention in RNNs\n",
    "<img src=\"https://jalammar.github.io/images/seq2seq_7.mp4\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84e7e7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Attention in detail\n",
    "<img src=\"https://jalammar.github.io/images/attention_process.mp4\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaba5c2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convolution neuronal networks (CNNs)\n",
    "<img src=\"https://lh3.googleusercontent.com/Zy5xK_i2F8sNH5tFtRa0SjbLp_CU7QwzS2iB5nf2ijIf_OYm-Q5D0SgoW9SmfbDF97tNEF7CmxaL-o6oLC8sGIrJ5HxWNk79dL1r7Rc=w2048-rw-v1\" />\n",
    "\n",
    "From [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab232a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## the Transformer\n",
    "<img src=\"http://jalammar.github.io/images/t/the_transformer_3.png\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db2953",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transformer under the hood\n",
    "<img src=\"http://jalammar.github.io/images/t/The_transformer_encoders_decoders.png\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d7292",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Encoder and decoder\n",
    "<img src=\"http://jalammar.github.io/images/t/Transformer_decoder.png\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94f5a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Word to vector by embedding algorithm (see [[5]](#references))\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/encoder_with_tensors.png\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35cbf6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Self-attendence at high level (see [2] for details)\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/transformer_self-attention_visualization.png\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc82de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More details\n",
    "* Multi-headed attention (multiple ways to look at references)\n",
    "* Positional encoding to represent the sequential order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ec4fe3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overall process - encoding / decoding\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/transformer_decoding_1.gif\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7fdf1f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overall process - decoding\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/transformer_decoding_2.gif\" />\n",
    "\n",
    "From [[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4ce12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training (see [[6]](#references))\n",
    "\n",
    "1. Unattended training on a huge datasets (Common Crawl, WebText2, Books1, Books2, Wikipedia)\n",
    "2. Fine-tune by learning supervised datasets\n",
    "3. Few-shot learning - give a prompt with a few examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3eb34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92fac9e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13\n",
      "What is 4 plus 5? A:\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "\"\"\"What is 7 plus 8? A: 15\n",
    "What is 3 plus 4? A: 7\n",
    "\n",
    "What is 6 plus 7? A:\"\"\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=10,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad2a6b3f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ten\n",
      "  What is nine plus one? A: ten\n",
      "  What is nine plus three? A: twelve\n",
      "  What is ten plus two? A: twelve\n",
      "  What is eleven plus two? A: thirteen\n",
      "  What is twelve\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"What is seven plus eight? A: fifteen\n",
    "  What is nine plus four? A: thirteen\n",
    "  What is six plus six? A: twelve\n",
    "  \n",
    "  What is eight plus two? A:\"\"\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=50,\n",
    "  presence_penalty=0.0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1febfce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12 times\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"Carrie is packing to move to another apartment down the hall. \n",
    "  She packed 24 boxes. Each box can hold up to 8 lbs. \n",
    "  The trolley she is using to move can take up to 32 lbs. \n",
    "  How many trips does it take her to move if she only has one trolley?\n",
    "  \n",
    "  Answer:\"\"\",\n",
    "  temperature=0.9,\n",
    "  max_tokens=50,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.6\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb272ce3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06b141f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " When she opened the door, he came in.\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"\n",
    "  Translate German to English:\n",
    "  Er sah den Vogel am Fenster. -> He saw the bird at the window.\n",
    "  Als sie die Tür öffnte, kam er herein. ->\"\"\",\n",
    "  temperature=0.9,\n",
    "  max_tokens=50,\n",
    "  stop=[\"\\n\", \"->\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "054728a3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gato\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"\n",
    "  Translate English to Spanish:\n",
    "  dog -> perro\n",
    "  cat -> \"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=50,\n",
    "  stop=[\"\\n\", \" ->\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb30164",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarize a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d0cc435",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA is a biological molecule that keeps the \"instructions\" for sustaining the\n",
      "\n",
      "growth, development, functioning and the reproduction of plants, animals and\n",
      "plausible scientists.\n",
      "\n",
      "Other \"Einstein wannabes\" followed Einstein and have done similar things by junk science. Stephen Hawking\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"Deoxyribonucleic acid (DNA) is a molecule composed of two polynucleotide chains that coil \n",
    "  around each other to form a double helix carrying genetic instructions for the development, \n",
    "  functioning, growth and reproduction of all known organisms and many viruses. DNA and \n",
    "  ribonucleic acid (RNA) are nucleic acids. Alongside proteins, lipids and complex \n",
    "  carbohydrates (polysaccharides), nucleic acids are one of the four major types of \n",
    "  macromolecules that are essential for all known forms of life.\n",
    "  \\\"\\\"\\\"\\nI rephrased it for him, in plain language a fifth grader can understand:\n",
    "  \\\"\\\"\\\"\\n\"\"\",\n",
    "  temperature=0.9,\n",
    "  max_tokens=60,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\\"\\\"\\\"\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd6acc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "    \"DNA is a molecule made of two chains, one made of sugar and the other of phosphate, that coil around each other to form a row of four nucleotides, repeated in the strand millions of times, like a sentence. At the end of each sentence there is one more nucleotide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8fde74b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bob was friends with Alice. Bob went to visit his friend \n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"Alice was friends with Bob. Alice went to visit her friend ____ \n",
    "  \"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=50,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.6,\n",
    "  stop=[\"____\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f26e2a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The barkeeper tells you: \"The corner gets a beer.\"\n",
      "\n",
      "You bring the woman a beer.\n",
      "\n",
      "The barkeeper tells you: \"The corner gets a beer.\"\n",
      "\n",
      "You bring the woman a beer.\n",
      "\n",
      "The barkeeper tells you: \"The corner gets a beer.\"\n",
      "\n",
      "You bring the woman a beer.\n",
      "\n",
      "The barkeeper tells you: \"The corner gets a beer.\"\n",
      "\n",
      "You bring the woman a beer.\n",
      "\n",
      "The barkeeper\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"A woman goes to a table near the corner. The barkeeper tells you: \"The corner gets a beer.\"\"\n",
    "  Whom you bring a beer?\n",
    "\"\"\",\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.6\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4d3df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mondegreen & Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59b8bd09",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? The most obvious interpretation is that \"the mares eat oats and the does eat oats and the little lambs eat ivy.\" But the word \"divey\", if interpreted as \"dividend\", implies that the lambs are eating a share of profits, which is not explained in the poem. Other interpretations include:\n",
      "\n",
      "The first recording of the song was made by Eddie Cantor in 1942 (on the Decca label). Cantor's version was recorded in the key of G minor.\n",
      "\n",
      "Since then, \"Mairzy Doats\" has been recorded by many artists and by many genres, including the accordion, Paul Robeson, The Andrew Sisters, The Ink Spots, and The Chipmunks.\n",
      "With its nonsense lyrics, \"Mairzy Doats\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"\n",
    "  Mairzy doats and dozy doats and liddle lamzy divey\n",
    "  A kiddley divey too, wouldn't you?\n",
    "  \\\"\\\"\\\"\n",
    "  What does the poem mean\"\"\",\n",
    "  temperature=0.8,\n",
    "  max_tokens=160,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\\"\\\"\\\"\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe409c6d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The poem is a sonnet with a rhyme scheme of \"ababcdcdefefgg\". The first line is a question, and the rest of the poem is the answer.\n",
      "\n",
      "Create a poem of John Donne:\n",
      "\n",
      "Batter my heart, three-person'd God; for, you\n",
      "As yet but knock; breathe, shine, and seek to mend;\n",
      "That I may rise, and stand, o'erthrow me, and bend\n",
      "Your\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"Create a poem of Dylan Thomas:\n",
    "  \"\"\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=100,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.6\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a78ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "627e76c7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mix the flour, salt, baking soda, butter, sugar, egg, milk, and vanilla extract. Put the dough on a baking sheet and bake it for about 10 minutes at 180 degrees Celsius. \n",
      "  Name: Apple Pie\n",
      "  Ingredients: apples, sugar, cinnamon, margarine, flour, eggs, vanilla extract, salt, baking powder, milk\n",
      "  Recipe: Mix the apples, sugar, cinnamon, margarine, flour, eggs, vanilla extract, salt, baking powder, and milk. Put the dough in a baking pan and bake it for about 30 minutes at 180 degrees Celsius. \n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"Name: Mother’s Pancakes\n",
    "  Ingredients: butter milk, flour, Eggs, sugar, soda \n",
    "  Recipe: Mix the milk, flour, eggs, and sugar well. Add the soda and keep it for about 10 minutes. Prepare a pan with margarine or olive oil. Put one ladle of the liquid into the pan and let it fill the pan ground. You can add currents if you want. Turn the golden pancake with a turner or a knife. Add some margarine if needed. Usually served at home with sweet fruits or apple sauce. \n",
    "\n",
    "  Name: Sugar Cookies\n",
    "  Ingredients: flour, salt, baking soda, butter, sugar, egg, milk, vanilla extract\n",
    "  Recipe:\"\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=500,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.6,\n",
    "  stop= [\"\\n\\n\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e83ead",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generate ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21edbb23",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A virtual museum\n",
      "Students can learn about history and art in a virtual museum.\n",
      "\n",
      "3. Virtual field trips\n",
      "Students can visit different places in the world without leaving their classroom.\n",
      "\n",
      "4. Virtual classes\n",
      "Virtual reality can be used to teach students.\n",
      "\n",
      "5. Immersive learning\n",
      "Students can learn through virtual reality.\n",
      "\n",
      "6. A virtual zoo\n",
      "Students can visit a virtual zoo and interact with animals.\n",
      "\n",
      "7. Virtual schools\n",
      "Students can attend virtual schools.\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "    \"\"\"Ideas involving education and virtual reality\n",
    "\n",
    "1. Virtual Mars\n",
    "Students get to explore Mars via virtual reality and go on missions to collect and catalog what they see.\n",
    "\n",
    "2.\"\"\",\n",
    "  temperature=0.9,\n",
    "  max_tokens=100,\n",
    "  top_p=0.5\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a2b11",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Chat bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05f9b0d7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I see. How old are you?\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"\n",
    "  The following is a conversation with an AI doctor. The doctor is helpful, professional, and very friendly.\n",
    "  \n",
    "  Human: Hello, I am sick.\n",
    "  AI: I am an AI doctor created by OpenAI. How do you feel?\n",
    "  Human: I feel fatigue and am moody.\n",
    "  AI:\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=150,\n",
    "  stop=[\"\\n\", \" Human:\", \" AI:\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a8c4372",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Morning sickness is an expected symptom for your pregnancy. Do you want to hear about options for morning sickness treatment?\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"\n",
    "  The following is a conversation with an AI doctor. The doctor is helpful, professional, and very friendly.\n",
    "  \n",
    "  Human: Hello, I am sick.\n",
    "  AI: I am an AI doctor created by OpenAI. How do you feel?\n",
    "  Human: I feel fatigue and am moody.\n",
    "  AI: What other symptons do you have?\n",
    "  Human: I have morning sickness.\n",
    "  AI:\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=150,\n",
    "  stop=[\"\\n\", \" Human:\", \" AI:\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e5eb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12877ecd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import Random\n",
      "a = random.randint(1,12)\n",
      "b = random.randint(1,12)\n",
      "for i in range(10):\n",
      "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
      "    answer = input(question)\n",
      "    if answer = a*b\\      \n",
      "        print (Well done!)\n",
      "    else:\n",
      "        print(\"No.\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"##### Fix bugs in the below function\n",
    "  \n",
    "### Buggy Python\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\\       \n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\\\"No.\\\")\n",
    "### Fixed Python\"\"\",\n",
    "  temperature=0 ,\n",
    "  max_tokens=182,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8292880",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fak n = if n > 1 then n * fak (n - 1) else 1\n",
      "\n",
      "The Haskell code is much shorter and easier to read.\n",
      "\n",
      "The following is a simple example of a recursive function in Python.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "  \"\"\"##### Translate this function from Python into Haskell\n",
    "### Python\n",
    "\n",
    "def fak(n):\n",
    "    if n > 1:\n",
    "        return(n*fak(n-1))\n",
    "    else:\n",
    "        return(1)\n",
    "        \n",
    "### Haskell\"\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=50,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e302cc9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      # Driver Code\n",
      "n = int(input())\n",
      "m = int(input())\n",
      "print(gcd(n,m))\n",
      "\n",
      "Calculate the sum of all the numbers between 1 to n. \n",
      "# Driver Code\n",
      "n = int(input())\n",
      "print(sum(range(1,n)))\n",
      "\n",
      "Calculate the sum of all the even numbers between 1 to n. \n",
      "# Driver Code\n",
      "n = int(input())\n",
      "print(sum(range(1,n),2))\n",
      "\n",
      "Calculate the sum of all the prime numbers between 1 to n. \n",
      "# Driver Code\n",
      "n = int(input())\n",
      "print(sum(range(1\n"
     ]
    }
   ],
   "source": [
    "print(gpt.submit_request(\n",
    "    \"\"\"Calculate factorial of number given by user in python.\n",
    "\n",
    "import math\n",
    "\n",
    "print(\"Enter a number: \")\n",
    "num = int(input())\n",
    "factorial_number = 1 \n",
    "for i in range(1, num + 1): \n",
    "    factorial_number *= i\n",
    "print(factorial_number)\n",
    "\n",
    "Write a program that returns the nth element of the Fibonacci Sequence in python.\n",
    "\n",
    "def Fibonacci(n):\n",
    "    if n<0:\n",
    "        print(\"Incorrect input\")\n",
    "    # First Fibonacci number is 0\n",
    "    elif n==0:\n",
    "        return 0\n",
    "    # Second Fibonacci number is 1\n",
    "    elif n==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return Fibonacci(n-1)+Fibonacci(n-2)\n",
    "\n",
    "# Driver Program\n",
    "n = int(input())\n",
    "print(Fibonacci(n)) \n",
    "\n",
    "Calculate the greatest common divisor of two numbers.\n",
    "  \"\"\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa20883",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Critics\n",
    "\n",
    "* OpenAI did not publically release GPT-3, the source code was made available to Microsoft only\n",
    "* Timnit Gebru et al - On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜 [[7]](#references), [[8]](#references)\n",
    "* Energy efficiency (~ several thousand Petaflop/s-day)\n",
    "* Usage for disinformation [[9]](#references)\n",
    "* Racism, extremist texts [[10]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962db832",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='references'></a>\n",
    "# Bibliography\n",
    "\n",
    "1. Christopher Olah, __Understanding LSTM Networks__, (http://colah.github.io/posts/2015-08-Understanding-LSTMs/), posted on August 27, 2015\n",
    "2. Jay Alammar, __Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)__ (https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/), written on May 9, 2018\n",
    "3. https://towardsdatascience.com/transformers-141e32e69591\n",
    "4. Aäron van den Oord, Sander Dieleman, __WaveNet: A generative model for raw audio__ ( https://deepmind.com/blog/article/wavenet-generative-model-raw-audio), September 8, 2016\n",
    "5. Jaron Collis, __Glossary of Deep Learning: Word Embedding__, (https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca), April 19, 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7e57d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "6. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei, __Language Models are Few-Shot Learners__, (https://arxiv.org/abs/2005.14165), 2020\n",
    "7. Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, Shmargaret Shmitchell, __On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜__, (https://dl.acm.org/doi/10.1145/3442188.3445922), March 2021\n",
    "8. Karen Ha, __MIT Technology review: We read the paper that forced Timnit Gebru out of Google. Here’s what it says.__, (https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/), December 4th, 2020\n",
    "9. Ben Buchanan (On leave) Andrew Lohn Micah Musser Katerina Sedova, __Truth, Lies, and Automatio - How Language Models Could Change Disinformation__, (https://cset.georgetown.edu/publication/truth-lies-and-automation/), May 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0101f60",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "10. Kris McGuffie, Alex Newhouse, __The Radicalization Risks of GPT-3 and Advanced Neural Language Models__, (https://arxiv.org/abs/2009.06807), September 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40483e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notebook on GitHub\n",
    "\n",
    "(https://github.com/toliman7/gpt-3)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
